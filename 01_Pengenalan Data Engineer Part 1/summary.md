Data Engineer adalah orang yang melakukan pengumpulan data mentah dari berbagai sumber (Data Ingestion), kemudian melakukan pembersihan dan transformasi seperti menyesuaikan format, menganalisis, dan lain-lain (Data Transformation), untuk kemudian disajikan (Data Serving) dan selanjutnya akan digunakan oleh Data Scientist maupun Data Analyst, serta sebagai arsip perusahaan. Beberapa skill yang dibutuhkan oleh seorang data engineer adalah pengetahuan dalam menguasai bahasa pemrograman, khususnya Python dan SQL untuk membuat dan mengakses database. Selain itu, pengetahuan tentang cloud server contohnya AWS dan GCP yang sering digunakan sebagai server oleh data engineer. Data Engineer juga sangat perlu menguasai aspek big data, mulai dari tools dan platform yang digunakan seperti Apache Hadoop, Spark, Hive, Scala, dan sejenisnya.

Data Pipeline adalah serangkaian langkah proses persiapan data untuk dianalisis. Data pipeline dapat dibagi berdasarkan urutan proses transformasinya (ETL dan ELT) dan berdasarkan sumber datanya (Batch dan Stream). ETL (Extract-Transform-Load) merupakan data pipeline yang mengekstrak data dari berbagai sumber kemudian disimpan ke dalam staging area (di dalamnya terdapat proses transformasi) dan dimuat dalam data lake/data warehouse. ETL (Extract-Load-Transform) mengekstrak data dan dimuat dalam data lake/data warehouse, kemudian baru akan ditransoformasikan saat akan digunakan. Batch memproses dan menganalisis data yang masuk secara periodik dan hasilnya disimpan ke dalam database/dibuat dalam bentuk laporan, sedangkan Stream memproses data yang masuk secara kontinu dan menghasilkan output real-time.