Data Engineer adalah orang yang melakukan pengumpulan data mentah dari berbagai sumber (Data Ingestion), kemudian melakukan pembersihan dan transformasi seperti menyesuaikan format, menganalisis, dan lain-lain (Data Transformation), untuk kemudian disajikan (Data Serving) dan selanjutnya akan digunakan oleh Data Scientist maupun Data Analyst, serta sebagai arsip perusahaan.

Data Pipeline adalah serangkaian langkah proses persiapan data untuk dianalisis. Data pipeline dapat dibagi berdasarkan urutan proses transformasinya (ETL dan ELT) dan berdasarkan sumber datanya (Batch dan Stream). ETL (Extract-Transform-Load) merupakan data pipeline yang mengekstrak data dari berbagai sumber kemudian disimpan ke dalam staging area (di dalamnya terdapat proses transformasi) dan dimuat dalam data lake/data warehouse. ETL (Extract-Load-Transform) mengekstrak data dan dimuat dalam data lake/data warehouse, kemudian baru akan ditransformasikan saat akan digunakan. Batch memproses dan menganalisis data yang masuk secara periodik dan hasilnya disimpan ke dalam database/dibuat dalam bentuk laporan, sedangkan Stream memproses data yang masuk secara kontinu dan menghasilkan output real-time.